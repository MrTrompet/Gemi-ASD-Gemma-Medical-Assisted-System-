ü©∫‚ù§Ô∏èGemi-ASD: Gemma-Powered Medical Assistant System

Gemi is an on-device medical assistant leveraging the power of Gemma 3n to provide crucial diagnoses and emergency guidance to millions, especially in low-resource settings without internet access.

üåü Project Vision

Our goal is to democratize access to critical health information. Gemi operates entirely on-device, ensuring that life-saving advice and medical assistance are available instantly, regardless of internet connectivity.

‚ú® Key Features

- Emergency Flow: A life-saving feature that provides immediate, actionable guidance in critical situations, such as a Red Alert for a high risk of CVA (stroke). It guides the user through a rapid diagnostic process and provides concise instructions.

- Pulsometer (15s Method): An innovative, sensorless tool that allows users to accurately check their pulse and heart rate. It provides a BPM count and a preliminary diagnosis (tachycardia, bradycardia) using a quick, 15-second manual count method, inspired by emergency room protocols.

- Medication Calendar: Simplifies medication management by allowing users to schedule reminders. The system can understand natural language input and generate a clear, manageable schedule to ensure patients adhere to their treatment.

- Medical Records Viewer: 
A built-in PDF viewer designed for easy access and review of personal medical records, ensuring all critical information is available in one place.

üõ†Ô∏è Technical Stack

- LLM: Gemma-3n-E2B-it-Q4_K_M.gguf - Unsloth

- Quantization: 4-bit (.gguf) using llama.cpp for optimal on-device performance.

- Framework: Python for the backend, with Flet for a multi-platform, cross-device graphical user interface (GUI).

üöÄ Demo and Installation

- YouTube Demo: Watch the full demonstration of Gemi's features and functionality here:
  ‚ñ∂Ô∏è https://www.youtube.com/watch?v=1Ofr-tD4PQw

- Executable (.exe): To test the application directly, download the compiled executable from our Google Drive.
  üìÇ https://drive.google.com/file/d/1pfiUnHVRXyYFDlg6kSTK3TaSBGV6DwrX/view?usp=sharing

üíª For Developers

Setup & Run from Source

To run the application from the source code, follow these steps:

Clone the Repository

Bash

git clone https://github.com/MrTrompet/Gemi-ASD-Gemma-Medical-Assisted-System-
cd Gemi-ASD-Gemma-Medical-Assisted-System-
Set up the Environment
Create a Python virtual environment and install the required dependencies.

Bash

# Create the virtual environment
python -m venv .venv

# Activate the virtual environment
# On Windows:
.venv\Scripts\activate
# On macOS/Linux:
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt
Download the Gemma 3n Model
The application requires the Gemma 3n 4-bit quantized model (.gguf). This file is not included in the repository due to its size.

Download the model: The model was generated using the Unsloth library. You can download the .gguf file from the following link: https://huggingface.co/bartowski/google_gemma-3n-E2B-it-GGUF

Place the Model
Create a new folder and place the downloaded model file in it.

./gemi_app
‚îú‚îÄ‚îÄ models-gemma3n/
‚îÇ   ‚îî‚îÄ‚îÄ gemma-3n-E2B-it-Q4_K_M.gguf
‚îî‚îÄ‚îÄ ...

üîßProject Structure: 

gemi_app/
‚îú‚îÄ app.py  # punto de entrada: carga el page, routes y llama a ft.app()
‚îú‚îÄ utils.py 
‚îú‚îÄ text_utils.py 
‚îú‚îÄ _init_.py
‚îú‚îÄ requirements.txt
‚îú‚îÄ .venv
‚îú‚îÄ > assets
‚îÇ    ‚îî‚îÄ Guarda el cache de Pdfs
‚îú‚îÄ llm/
‚îÇ   ‚îú‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ prompt_builder.py
‚îÇ   ‚îî‚îÄ gemma_wrapper.py 
‚îú‚îÄ views/
‚îÇ   ‚îú‚îÄ logo.py      # build_logo_view()
‚îÇ   ‚îú‚îÄ privacy.py   # build_privacy_view()
‚îÇ   ‚îú‚îÄ onboarding.py# build_gender_view(), build_age_view(), build_antecedents_view()
‚îÇ   ‚îú‚îÄ main.py      # build_main_view(), set_tab(), toggle_drawer()
‚îÇ   ‚îú‚îÄ emergency.py # build_emergency_tab()
‚îÇ   ‚îú‚îÄ medichat.py  # build_medichat_tab()
‚îÇ   ‚îú‚îÄ profile.py   # build_profile_view()
‚îÇ   ‚îú‚îÄ pdf_viewer_proc.py
‚îÇ   ‚îú‚îÄ pdf_image_viewer.py
‚îÇ   ‚îú‚îÄ pdf_text_viewer.py
‚îÇ   ‚îú‚îÄ _init_.py
‚îÇ   ‚îú‚îÄ calendario.py
‚îÇ   ‚îú‚îÄ pulsometro.py
‚îÇ   ‚îú‚îÄ emergency_button.py
‚îÇ   ‚îî‚îÄ settings.py  # build_settings_view()
‚îî‚îÄ models\gemma3n
‚îÇ    ‚îú‚îÄ gemma-3n-2b-it-gguf
‚îÇ         ‚îú‚îÄ >.cache
‚îÇ         ‚îÇ     ‚îú‚îÄ >download
‚îÇ         ‚îÇ     ‚îÇ     ‚îî‚îÄ gemma-3n-E2B-it-Q4_K_M.gguf.metadata
‚îÇ         ‚îÇ     ‚îî‚îÄ .gitignore
‚îÇ         ‚îî‚îÄ gemma-3n-E2B-it-Q4_K_M.gguf            
‚îî‚îÄ data/
‚îÇ     ‚îú‚îÄ > pdfs
‚îÇ     ‚îú‚îÄ > photos
‚îÇ     ‚îú‚îÄ chat_data.json
‚îÇ     ‚îú‚îÄ profile_data.json
‚îÇ     ‚îî‚îÄ gemi_user_data.json


Run the Application
With the virtual environment active and the model in place, you can run the application.

Bash

python app.py

‚öôÔ∏è Challenges and Lessons Learned
This project was a journey of technical problem-solving. A major challenge was optimizing the model for low-end hardware.

The Quantization Pivot: I initially attempted to quantize the model to 8-bit using ONNX Runtime. However, this method proved to be too heavy for the target hardware. As a result, I decided to pivot to a more effective method, successfully using llama.cpp to achieve a highly efficient 4-bit (.gguf) model that runs flawlessly on a standard CPU.

Experimentation Notebook: For full transparency, the notebook detailing the attempted 8-bit ONNX quantization is available in this repository.

ü§ù Connect and Contribute
I am very interested in receiving your feedback to continue improving and developing this application in the future. Feel free to contact me or open an issue on this repository.
